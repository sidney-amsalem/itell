---
assignments:
- summary
chunks:
- title: Learning Objectives
  slug: Learning-Objectives-260pt
  type: plain
- title: Conceptually Defining the Construct
  slug: Conceptually-Defining-the-Construct-892t
  type: regular
- title: Operationally Defining the Construct
  slug: Operationally-Defining-the-Construct-894t
  type: regular
  headings:
  - level: 3
    slug: using-an-existing-measure
    title: Using an Existing Measure
- title: Operationally Defining the Construct 2
  slug: Operationally-Defining-the-Construct-2-893t
  type: regular
  headings:
  - level: 3
    slug: creating-your-own-measure
    title: Creating Your Own Measure
- title: Implementing the Measure
  slug: Implementing-the-Measure-895t
  type: regular
- title: Evaluating the Measure
  slug: Evaluating-the-Measure-896t
  type: regular
- title: References
  slug: References-261pt
  type: plain
cri:
- question: Why is having a clear and complete conceptual definition of a construct important for good measurement?
  answer: It allows you to make sound decisions about how to measure the construct effectively.
  slug: Conceptually-Defining-the-Construct-892t
- question: Why is it usually a good idea to use an existing measure when operationally defining a variable?
  answer: You save time, benefit from existing evidence of validity, and facilitate comparison with previous research results.
  slug: Operationally-Defining-the-Construct-894t
- question: Why is it important to strive for simplicity when creating a new measure?
  answer: To ensure that participants can understand and carry out the task without becoming bored or frustrated, leading to unreliable responses.
  slug: Operationally-Defining-the-Construct-2-893t
- question: How can researchers minimize participants' reactivity in studies?
  answer: Researchers can make procedures clear and brief, guarantee anonymity, seat participants far apart in groups, use the same writing implement for all, ensure questionnaires are sealed immediately, avoid revealing hypotheses, and standardize interactions between researchers and participants.
  slug: Implementing-the-Measure-895t
- question: How should researchers proceed if their newly collected data cast doubt on the reliability or validity of their measure?
  answer: Researchers should investigate potential issues with the measure, administration, conceptual definition, or experimental manipulation to determine the cause of the doubt.
  slug: Evaluating-the-Measure-896t
next_slug: page-12
order: 21
parent:
  title: IV. Psychological Measurement
  slug: iv-psychological-measurement
quiz:
- question: "1.\tWhich of the following best establishes validity when it comes to a psychological measurement?"
  answers:
  - answer: "a.\tThe measure represents the variable the researcher intends to measure "
    correct: true
  - answer: "b.\tThe measure produces stable and consistent results"
    correct: false
  - answer: "c.\tThe measure produces results that are consistent with the hypothesis"
    correct: false
  - answer: "d.\tThe measure easy to understand and implement"
    correct: false
- question: "2.\tTo establish the reliability of a measure of personality, a researcher will often have individuals complete the questionnaire on two separate occasions to make sure their responses are similar across time. What type of reliability is demonstrated here? "
  answers:
  - answer: "a.\tSplit-half reliability"
    correct: false
  - answer: "b.\tInternal reliability"
    correct: false
  - answer: "c.\tTest-retest reliability"
    correct: true
  - answer: "d.\tInter-rater reliability"
    correct: false
- question: "3.\tTwo observers record similar observations on a behavioral rating scale for a group of children they are watching. The researchers have established what kind of reliability?"
  answers:
  - answer: "a.\tSplit-half reliability"
    correct: false
  - answer: "b.\tInternal reliability"
    correct: false
  - answer: "c.\tTest-retest reliability"
    correct: false
  - answer: "d.\tInter-rater reliability"
    correct: true
- question: "4.\tYou produce a new measure of emotional intelligence, and you find that this new measure does not correlate with cognitive tests of intelligence, suggesting to you that these constructs are different. What type of validity have you demonstrated?"
  answers:
  - answer: "a.\tFace validity"
    correct: false
  - answer: "b.\tContent validity"
    correct: false
  - answer: "c.\tCriterion validity"
    correct: false
  - answer: "d.\tDiscriminant validity"
    correct: true
- question: "5.\tA teacher separates students into three groups based on their level of performance on a math test (low, medium, and high performance), and plans to teach differently to the three groups. What scale of measurement is being used to create the three groups of students? "
  answers:
  - answer: "a.\tNominal"
    correct: false
  - answer: "b.\tOrdinal"
    correct: true
  - answer: "c.\tInterval"
    correct: false
  - answer: "d.\tRatio"
    correct: false
- question: "6.\tWhich of the following is true about psychological or mental “constructs” like self-esteem or happiness?"
  answers:
  - answer: "a.\tThey can be measured directly"
    correct: false
  - answer: "b.\tThey cannot be measured at all"
    correct: false
  - answer: "c.\tThey can be measured indirectly via operational definitions"
    correct: true
  - answer: "d.\tThey don’t exist because they are all in your mind"
    correct: false
- question: "7.\tFor which type of scale is it impossible to calculate a mean and standard deviation? "
  answers:
  - answer: "a.\tNominal"
    correct: true
  - answer: "b.\tInterval"
    correct: false
  - answer: "c.\tRatio"
    correct: false
  - answer: "d.\tYou can calculate a mean and standard deviation for all of these"
    correct: false
- question: "8.\tWhich of the following demonstrates an example of socially desirable responding on a self-reported measure?"
  answers:
  - answer: "a.\tA participant falsely claims that they have experienced hallucinations because they want to mess with the researchers"
    correct: false
  - answer: "b.\tA participant falsely claims that they have never smoked cigarettes because they think that this is the socially appropriate response"
    correct: true
  - answer: "c.\tA participant provides false responses by randomly clicking buttons to get through a survey more quickly"
    correct: false
  - answer: "d.\tAll of the above"
    correct: false
- question: "9.\tWhich of the following is a “behavioral” measure of amount of sleep?"
  answers:
  - answer: "a.\tParticipant complete a survey reporting how much they slept on each of the previous 7 days"
    correct: false
  - answer: "b.\tParticipants are observed for 7 days and the time they go to bed and when they wake up is recorded each day"
    correct: false
  - answer: "c.\tParticipants wear a sleep tracker for 7 days, which measures their heart rate, body temperature, and breathing rate to indicate how much they sleep"
    correct: true
  - answer: "d.\tParticipants are provided with melatonin which may help them sleep more"
    correct: false
- question: "10.\tIn terms of operational definitions, what does it mean to say that researchers use “converging operations” in the measurement of psychological constructs?"
  answers:
  - answer: "a.\tThey use more than one operational definition to get a better estimate of the construct"
    correct: true
  - answer: "b.\tThey survey different researchers about the measurements they use to converge on the most preferred measurement"
    correct: false
  - answer: "c.\tThey try out different types of measurement and converge on the true one though evidence"
    correct: false
  - answer: "d.\tThey observe behaviors for enough time that the observations converge on a reliable conclusion"
    correct: false
- question: "11.\tA researcher believes that the construct of “personality” involves 5 separate traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism). They then create a measure of personality that only includes a single item (“do you have a good personality?”) and doesn’t cover that whole construct. What is the primary issue with this measurement?"
  answers:
  - answer: "a.\tIt lacks reliability"
    correct: false
  - answer: "b.\tIt lacks content validity"
    correct: true
  - answer: "c.\tIt lacks criterion validity"
    correct: false
  - answer: "d.\tIt lacks discriminant validity"
    correct: false
- question: "12.\tWhen conducting your own study, what does your textbook recommend about using existing measures, rather than creating your own?"
  answers:
  - answer: "a.\tUsing existing measures is not recommended"
    correct: false
  - answer: "b.\tUsing existing measures is not allowed"
    correct: false
  - answer: "c.\tUsing existing measures is required"
    correct: false
  - answer: "d.\tUsing existing measures is usually a good idea"
    correct: true
slug: 21-practical-strategies-for-psychological-measurement
title: 21. Practical Strategies for Psychological Measurement
---

## Learning Objectives {#Learning-Objectives-260pt .sr-only} 

<i-callout variant="info" title="Learning Objectives">

1\. Specify the four broad steps in the measurement process.

2\. Explain how you would decide whether to use an existing measure or create your own.

3\. Describe multiple strategies to identify and locate existing measures of psychological constructs.

4\. Describe several general principles for creating new measures and for implementing existing and new measures.

5\. Create a simple plan for assessing the reliability and validity of an existing or new measure.

</i-callout>

So far in this chapter, we have considered several basic ideas about the nature of psychological constructs and their measurement. But now imagine that you are in the position of actually having to measure a psychological construct for a research project. How should you proceed? Broadly speaking, there are four steps in the measurement process: (a) conceptually defining the construct, (b) operationally defining the construct, (c) implementing the measure, and (d) evaluating the measure. In this section, we will look at each of these steps in turn.

## Conceptually Defining the Construct {#Conceptually-Defining-the-Construct-892t} 

Having a clear and complete conceptual definition of a construct is a prerequisite for good measurement. For one thing, it allows you to make sound decisions about exactly how to measure the construct. If you had only a vague idea that you wanted to measure people’s “memory,” for example, you would have no way to choose whether you should have them remember a list of vocabulary words, a set of photographs, a newly learned skill, an experience from long ago, or have them remember to perform a task at a later time. Because psychologists now conceptualize memory as a set of semi-independent systems, you would have to be more precise about what you mean by “memory.” If you are interested in long-term episodic memory (memory for previous experiences), then having participants remember a list of words that they learned last week would make sense, but having them try to remember to execute a task in the future would not. In general, there is no substitute for reading the research literature on a construct and paying close attention to how others have defined it.

## Operationally Defining the Construct {#Operationally-Defining-the-Construct-894t} 

Once you have a conceptual definition of the construct you are interested in studying it is time to operationally define the construct. Recall an operational definition is a definition of the variable in terms of precisely how it is to be measured. Since most variables are relatively abstract concepts that cannot be directly observed (e.g., stress), and observation is at the heart of the scientific method, conceptual definitions must be transformed into something that can be directly observed and measured. Most variables can be operationally defined in many different ways. For example, stress can be operationally defined as people’s scores on a stress scale such as the Perceived Stress Scale (Cohen, Kamarck, & Mermelstein, 1983) \[1\], cortisol concentrations in their saliva, or the number of stressful life events they have recently experienced. As described below, operationally defining your variable(s) of interest may involve using an existing measure or creating your own measure.

### Using an Existing Measure {#using-an-existing-measure}

It is usually a good idea to use an existing measure that has been used successfully in previous research. Among the advantages are that (a) you save the time and trouble of creating your own, (b) there is already some evidence that the measure is valid (if it has been used successfully), and (c) your results can more easily be compared with and combined with previous results. In fact, if there already exists a reliable and valid measure of a construct, other researchers might expect you to use it unless you have a good and clearly stated reason for not doing so.

If you choose to use an existing measure, you may still have to choose among several alternatives. You might choose the most common one, the one with the best evidence of reliability and validity, the one that best measures a particular aspect of a construct that you are interested in (e.g., a physiological measure of stress if you are most interested in its underlying physiology), or even the one that would be easiest to use. For example, the Ten-Item Personality Inventory (TIPI) is a self-report questionnaire that measures all the Big Five personality dimensions with just 10 items (Gosling, Rentfrow, & Swann, 2003)\[2\]. It is not as reliable or valid as longer and more comprehensive measures, but a researcher might choose to use it when testing time is severely limited.

When an existing measure was created primarily for use in scientific research, it is usually described in detail in a published research article and is free to use in your own research—with a proper citation. You might find that later researchers who use the same measure describe it only briefly but provide a reference to the original article, in which case you would have to get the details from the original article. The American Psychological Association also publishes the __Directory of Unpublished Experimental Measures__ and __PsycTESTS__, which are extensive catalogs/collections of measures that have been used in previous research. Many existing measures—especially those that have applications in clinical psychology—are proprietary. This means that a publisher owns the rights to them and that you would have to purchase them. These include many standard intelligence tests, the Beck Depression Inventory, and the Minnesota Multiphasic Personality Inventory (MMPI). Details about many of these measures and how to obtain them can be found in other reference books, including __Tests in Print__ and the __Mental Measurements Yearbook__. There is a good chance you can find these reference books in your university library.

## Operationally Defining the Construct 2 {#Operationally-Defining-the-Construct-2-893t .sr-only} 

### Creating Your Own Measure {#creating-your-own-measure}

Instead of using an existing measure, you might want to create your own. Perhaps there is no existing measure of the construct you are interested in or existing ones are too difficult or time-consuming to use. Or perhaps you want to use a new measure specifically to see whether it works in the same way as existing measures—that is, to evaluate convergent validity. In this section, we consider some general issues in creating new measures that apply equally to self-report, behavioral, and physiological measures. More detailed guidelines for creating self-report measures are presented in Chapter 7.

First, be aware that most new measures in psychology are really variations of existing measures, so you should still look to the research literature for ideas. Perhaps you can modify an existing questionnaire, create a paper-and-pencil version of a measure that is normally computerized (or vice versa), or adapt a measure that has traditionally been used for another purpose. For example, the famous Stroop task (Stroop, 1935)\[3\]—in which people quickly name the colors that various color words are printed in—has been adapted for the study of social anxiety. People high in social anxiety are slower at color naming when the words have negative social connotations such as “stupid” (Amir, Freshman, & Foa, 2002)\[4\].

When you create a new measure, you should strive for simplicity. Remember that your participants are not as interested in your research as you are and that they will vary widely in their ability to understand and carry out whatever task you give them. You should create a set of clear instructions using simple language that you can present in writing or read aloud (or both). It is also a good idea to include one or more practice items so that participants can become familiar with the task, and to build in an opportunity for them to ask questions before continuing. It is also best to keep the measure brief to avoid boring or frustrating your participants to the point that their responses start to become less reliable and valid.

The need for brevity, however, needs to be weighed against the fact that it is nearly always better for a measure to include multiple items rather than a single item. There are two reasons for this. One is a matter of content validity. Multiple items are often required to cover a construct adequately. The other is a matter of reliability. People’s responses to single items can be influenced by all sorts of irrelevant factors—misunderstanding the particular item, a momentary distraction, or a simple error such as checking the wrong response option. But when several responses are summed or averaged, the effects of these irrelevant factors tend to cancel each other out to produce more reliable scores. Remember, however, that multiple items must be structured in a way that allows them to be combined into a single overall score by summing or averaging. To measure “financial responsibility,” a student might ask people about their annual income, obtain their credit score, and have them rate how “thrifty” they are—but there is no obvious way to combine these responses into an overall score. To create a true multiple-item measure, the student might instead ask people to rate the degree to which 10 statements about financial responsibility describe them on the same five-point scale.

Finally, the very best way to assure yourself that your measure has clear instructions, includes sufficient practice, and is an appropriate length is to test several people. Observe them as they complete the task, time them, and ask them afterward to comment on how easy or difficult it was, whether the instructions were clear, and anything else you might be wondering about. Obviously, it is better to discover problems with a measure before beginning any large-scale data collection.

## Implementing the Measure {#Implementing-the-Measure-895t} 

You will want to implement any measure in a way that maximizes its reliability and validity. In most cases, it is best to test everyone under similar conditions that, ideally, are quiet and free of distractions. Participants are often tested in groups because it is efficient, but be aware that it can create distractions that reduce the reliability and validity of the measure. As always, it is good to use previous research as a guide. If others have successfully tested people in groups using a particular measure, then you should consider doing it too.

Be aware also that people can react in a variety of ways to being measured that reduce the reliability and validity of the scores. Although some disagreeable participants might intentionally respond in ways meant to disrupt a study, participant reactivity is more likely to take the opposite form. Agreeable participants might respond in ways they believe they are expected to. Some participants might engage in **socially desirable responding**, doing or saying things because they think it is the socially appropriate thing. For example, people with low self-esteem agree that they feel they are a person of worth not because they really feel this way but because they believe this is the socially appropriate response and do not want to look bad in the eyes of the researcher. Additionally, research studies can have built-in **demand characteristics**: subtle cues that reveal how the researcher expects participants to behave. For example, a participant whose attitude toward exercise is measured immediately after she is asked to read a passage about the dangers of heart disease might reasonably conclude that the passage was meant to improve her attitude. As a result, she might respond more favorably because she believes she is expected to by the researcher. Finally, your own expectations can bias participants’ behaviors in unintended ways.

There are several precautions you can take to minimize these kinds of reactivity. One is to make the procedure as clear and brief as possible so that participants are not tempted to vent their frustrations on your results. Another is to guarantee participants’ anonymity and make clear to them that you are doing so. If you are testing them in groups, be sure that they are seated far enough apart that they cannot see each other’s responses. Give them all the same type of writing implement so that they cannot be identified by, for example, the pink glitter pen that they used. You can even allow them to seal completed questionnaires into individual envelopes or put them into a drop box where they immediately become mixed with others’ questionnaires. Although informed consent requires telling participants what they will be doing, it does not require revealing your hypothesis or other information that might suggest to participants how you expect them to respond. A questionnaire designed to measure financial responsibility need not be titled “Are You Financially Responsible?” It could be titled “Money Questionnaire” or have no title at all. Finally, the effects of your expectations can be minimized by arranging to have the measure administered by a helper who is “blind” or unaware of its intent or of any hypothesis being tested. Regardless of whether this is possible, you should standardize all interactions between researchers and participants—for example, by always reading the same set of instructions word for word.

## Evaluating the Measure {#Evaluating-the-Measure-896t} 

Once you have used your measure on a sample of people and have a set of scores, you are in a position to evaluate it more thoroughly in terms of reliability and validity. Even if the measure has been used extensively by other researchers and has already shown evidence of reliability and validity, you should not assume that it worked as expected for your particular sample and under your particular testing conditions. Regardless, you now have additional evidence bearing on the reliability and validity of the measure, and it would make sense to add that evidence to the research literature.

In most research designs, it is not possible to assess test-retest reliability because participants are tested at only one time. For a new measure, you might design a study specifically to assess its test-retest reliability by testing the same set of participants at two separate times. In other cases, a study designed to answer a different question still allows for the assessment of test-retest reliability. For example, a psychology instructor might measure his students’ attitude toward critical thinking using the same measure at the beginning and end of the semester to see if there is any change. Even if there is no change, he could still look at the correlation between students’ scores at the two times to assess the measure’s test-retest reliability. It is also customary to assess internal consistency for any multiple-item measure—usually by looking at a split-half correlation or Cronbach’s α.

Criterion validity can be assessed in various ways. For example, if your study included more than one measure of the same construct or measures of conceptually distinct constructs, then you should look at the correlations among these measures to be sure that they fit your expectations. Note also that a successful experimental manipulation also provides evidence of criterion validity. Recall that MacDonald and Martineau manipulated participant’s moods by having them think either positive or negative thoughts, and after the manipulation, their mood measure showed a distinct difference between the two groups. This simultaneously provided evidence that their mood manipulation worked __and__ that their mood measure was valid.

But what if your newly collected data cast doubt on the reliability or validity of your measure? The short answer is that you have to ask why. It could be that there is something wrong with your measure or how you administered it. It could be that there is something wrong with your conceptual definition. It could be that your experimental manipulation failed. For example, if a mood measure showed no difference between people whom you instructed to think positive versus negative thoughts, maybe it is because the participants did not actually think the thoughts they were supposed to or that the thoughts did not actually affect their moods. In short, it is “back to the drawing board” to revise the measure, revise the conceptual definition, or try a new manipulation.

## References {#References-261pt} 

1.  Cohen, S., Kamarck, T., & Mermelstein, R. (1983). A global measure of perceived stress. _Journal of Health and Social Behavior, 24_, 386-396.
2.  Gosling, S. D., Rentfrow, P. J., & Swann, W. B., Jr. (2003). A very brief measure of the Big Five personality domains. _Journal of Research in Personality, 37_, 504–528.
3.  Stroop, J. R. (1935). Studies of interference in serial verbal reactions. _Journal of Experimental Psychology, 18_, 643–662.
4.  Amir, N., Freshman, M., & Foa, E. (2002). Enhanced Stroop interference for threat in social phobia. _Journal of Anxiety Disorders, 16_, 1–9.

